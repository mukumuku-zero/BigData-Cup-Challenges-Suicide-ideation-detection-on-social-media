{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZI_uTi_TwYBS","executionInfo":{"status":"ok","timestamp":1725700383950,"user_tz":-480,"elapsed":27856,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}},"outputId":"20968b2a-be0c-4bad-c1d4-887c669563df"},"id":"ZI_uTi_TwYBS","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["# Prediction Phase"],"metadata":{"id":"qlK2e-mZwYq6"},"id":"qlK2e-mZwYq6"},{"cell_type":"code","execution_count":1,"id":"10e9fdb1-7598-4bb3-9c6b-008e5861ede2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10e9fdb1-7598-4bb3-9c6b-008e5861ede2","executionInfo":{"status":"ok","timestamp":1725700180770,"user_tz":-480,"elapsed":3820,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}},"outputId":"e5ce95f8-eedb-4cb5-8faa-b45ff703879b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Exception in thread Thread-5 (attachment_entry):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 237, in listen\n","    sock, _ = endpoints_listener.accept()\n","  File \"/usr/lib/python3.10/socket.py\", line 293, in accept\n","    fd, addr = self._accept()\n","TimeoutError: timed out\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy.py\", line 52, in attachment_entry\n","    debugpy.listen(_dap_port)\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/public_api.py\", line 31, in wrapper\n","    return wrapped(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 143, in debug\n","    log.reraise_exception(\"{0}() failed:\", func.__name__, level=\"info\")\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 141, in debug\n","    return func(address, settrace_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 251, in listen\n","    raise RuntimeError(\"timed out waiting for adapter to connect\")\n","RuntimeError: timed out waiting for adapter to connect\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]}],"source":["import pandas as pd\n","import re\n","import demoji\n","import jaconv\n","from nltk.corpus import words\n","import nltk\n","from xml.sax.saxutils import unescape\n","\n","# Download the dictionary by uncommenting the following line only the first time it is run\n","# nltk.download('words')\n","\n","# Get a list of English words from nltk\n","english_words = set(words.words())\n","\n","# Regular expression patterns for detecting URLs\n","url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n","\n","def confirm_URL(df, url_pattern):\n","    # Checks each line of text for URLs and deletes lines that contain them\n","    df = df[~df['post'].str.contains(url_pattern, na=False)]\n","\n","    return df\n","\n","def convert_to_halfwidth(text):\n","    return jaconv.z2h(text, kana=False, ascii=True, digit=True)\n","\n","def replace_words(df, column, replacements):\n","    \"\"\"\n","    Replaces a word in the text of the specified column of the data frame\n","\n","    :param df: Data Frame\n","    :param column: Name of column containing text\n","    :param replacements: Dictionary of words to be replaced (keys are before replacement, values are after replacement)\n","    \"\"\"\n","    df[column] = df[column].apply(lambda x: ' '.join([replacements.get(word, word) for word in x.split()]))\n","    return df\n","\n","def text_conversion(text):\n","    \"\"\"\n","    Converting text to complex\n","\n","    :param text: text\n","    \"\"\"\n","\n","    # Decode encoded strings using unescape\n","    text = unescape(text)\n","\n","    # Delete pictograms\n","    text = demoji.replace(string=text, repl='')\n","\n","    # Convert to half-width characters\n","    text = convert_to_halfwidth(text)\n","\n","    # Delete hashtags\n","    text = text.replace(';', '; ')\n","    text = re.sub(r'#.*', \"\", text)\n","\n","    # Various symbol processing\n","    text = re.sub(r'\\！', '!', text)\n","    text = re.sub(r'\\!+', '.', text)\n","\n","    text = re.sub(r'\\？', '?', text)\n","    text = re.sub(r'\\‽', '?', text)\n","    text = re.sub(r'\\?+', '.', text)\n","\n","    text = re.sub(r'\\．', '.', text)\n","    text = re.sub(r'\\.+', '.', text)\n","\n","    text = re.sub(r'\\，', ',', text)\n","    text = re.sub(r'\\,+', ',', text)\n","\n","    text = re.sub(r'\\【', '[', text)\n","    text = re.sub(r'\\「', '[', text)\n","    text = re.sub(r'\\[+', '', text)\n","\n","    text = re.sub(r'\\】', ']', text)\n","    text = re.sub(r'\\」', ']', text)\n","    text = re.sub(r'\\]+', '', text)\n","\n","    text = re.sub(r'\\）', ')', text)\n","    text = re.sub(r'\\)+', '', text)\n","\n","    text = re.sub(r'\\（', '(', text)\n","    text = re.sub(r'\\(+', '', text)\n","\n","    text = re.sub(r'\\＿', '_', text)\n","    text = re.sub(r'\\_+', ' ', text)\n","\n","    # Delete URLs\n","    text = re.sub(r\"(https?|ftp)(:\\/\\/[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+\\$,%#]+)\", \"\" ,text)\n","    text = text.replace('…', '').replace('²', '').replace('*', '').replace('%', 'percent').replace('; -;', '').replace('.,', '.').replace('. ,', '.').replace(' .', '.')\n","    text = text.replace('xa0,', '').replace('xa0', '').replace('amp;', '').replace('&', 'and').replace('@', 'at').replace('=', 'is').replace('+', '')\n","    text = text.replace('percent', ' percent').replace('yo', ' yo')\n","    # text = text.replace('Removed', '').replace('Removed,', '').replace('Removed.', '')\n","\n","    # Add spaces after “.” or “,” if there are no spaces\n","    text = text.replace('.', '. ').replace(',', ', ')\n","\n","    # Remove white space at the beginning and end of sentences\n","    text = text.strip()\n","\n","    # Replace consecutive spaces with a single space\n","    text = re.sub(r'\\s+', ' ', text)\n","\n","    text = text.replace('\"', '').replace(\"'\", '').replace(\":\", '').replace(\"Id\", 'I would')\n","\n","    text = text.lower()\n","\n","    # Newline code deletion\n","    text = text.replace('\\n', '').replace('\\r', '').replace('\\t', '').replace('\\\\n', '').replace('\\\\r', '').replace('\\\\t', '').replace('\\\\', '')\n","\n","    return text\n","\n","def capitalize_i(text):\n","    # Replace single 'i' with 'I'\n","    text = re.sub(r'\\bi\\b', 'I', text)\n","    # Replace 'i' in 'i'm' and 'i'll' with 'I'\n","    text = re.sub(r\"\\bi'\", \"I'\", text)\n","\n","    return text\n","\n","def capitalize_sentences_initial(text):\n","    \"\"\"\n","    Capitalize the first letter of each sentence.\n","\n","    :param text: sentence\n","    :return: String with the first letter of each sentence capitalized\n","    \"\"\"\n","    sentences = re.split(r'(?<=[.!?]) +', text)\n","    sentences = [s.capitalize() for s in sentences]\n","    return ' '.join(sentences)\n","\n","# Dictionary of words to be replaced\n","replacements = {\n","    \"im\": \"I am\",\n","    \"iam\": \"I am\",\n","    \"i'm\": \"I am\",\n","    \"Im\": \"I am\",\n","    \"I'm\": \"I am\",\n","    \"Ive\": \"I have\",\n","    \"I'd\": \"I would\",\n","    \"ive\": \"I have\",\n","    \"i'd\": \"I would\",\n","    \"tbh\": \"to be honest\",\n","    \"kinda\": \"kind of\",\n","    \"cuz\": \"because\",\n","    \"geez\": \"jesus christ\",\n","    \"ill\": \"i'll\",\n","    \"Id\": \"i'd\",\n","    \"didnt\": \"didn't\",\n","    \"dont\": \"don't\",\n","    \"doesnt\": \"doesn't\",\n","    \"cant\": \"can't\",\n","    \"isnt\": \"isn't\",\n","    \"arent\": \"aren't\",\n","    \"wasnt\": \"wasn't\",\n","    \"werent\": \"weren't\",\n","    \"havent\": \"haven't\",\n","    \"hasnt\": \"hasn't\",\n","    \"hadnt\": \"hadn't\",\n","    \"wont\": \"won't\",\n","    \"wouldnt\": \"wouldn't\",\n","    \"shouldnt\": \"shouldn't\",\n","    \"couldnt\": \"couldn't\",\n","    \"mustnt\": \"mustn't\",\n","    \"shes\": \"she's\",\n","    \"hes\": \"he's\",\n","    \"its\": \"it's\",\n","    \"thats\": \"that's\",\n","    \"theres\": \"there's\",\n","    \"heres\": \"here's\",\n","    \"whos\": \"who's\",\n","    \"whats\": \"what's\",\n","    \"whys\": \"why's\",\n","    \"hows\": \"how's\",\n","    \"lets\": \"let's\",\n","    \"id've\": \"i'd have\",\n","    \"could've\": \"could have\",\n","    \"would've\": \"would have\",\n","    \"should've\": \"should have\",\n","    \"we're\": \"we are\",\n","    \"they're\": \"they are\",\n","    \"i'll\": \"I will\",\n","    \"you're\": \"you are\",\n","    \"it's\": \"it is\",\n","    \"idk\": \"I do not know\",\n","    \"we’re\": \"we are\",\n","    \"they’re\": \"they are\",\n","    \"i’ll\": \"I will\",\n","    \"you’re\": \"you are\",\n","    \"it’s\": \"it is\",\n","    \"id’ve\": \"i'd have\",\n","    \"could’ve\": \"could have\",\n","    \"would’ve\": \"would have\",\n","    \"should’ve\": \"should have\",\n","    \"kms\": \"kill myself\",\n","    \"laxy\": \"lazy\",\n","    \"fr\": \"for real\",\n","    \"dont\": \"do not\",\n","    \"plz\": \"please\",\n","    \"irl\": \"in real life\",\n","    \"meim\": \"maim\",\n","    \"imma\": \"I am going to\",\n","    \"ffs\": \"offs\",\n","    \"theyre\": \"they are\",\n","    \"dunno\": \"do not know\",\n","    \"ofc\": \"of course\",\n","    \"wouldk\": \"would\",\n","    \"cantdo\": \"can not do\",\n","    \"tw\": \"two\",\n","    \"harmi\": \"harm, i\",\n","    \"retardi\": \"retard i\",\n","    \"fem\": \"females\",\n","    \"dont\": \"do not\",\n","    \"coz\": \"because\",\n","    \"sch\": \"school\",\n","    \"u\": \"you\",\n","    \"bf\": \"boyfriend\",\n","    \"boy friend\": \"boyfriend\",\n","    \"girl friend\": \"girlfriend\",\n","    \"em\": \"them\",\n","    \"nobodyll\": \"nobody will\",\n","    \"h it\": \"hit\",\n","    \"schoo\": \"school\",\n","    \"xcuse me\": \"excuse me\",\n","    \"wasnt\": \"was not\",\n","    \"tgere\": \"there\",\n","    \"don\": \"do not\",\n","    \"didn\": \"did not\",\n","    \"4kdjejdne sjdjd fuckdjejekieirieiriodidieiridodiodididodidookdkekekdkoeooeoi\": \"i\",\n","    \"yt\": \"yet\",\n","    \"scaared\": \"scared\",\n","    \"fwiled\": \"failed\",\n","    \"wxpecter\": \"expected\",\n","    \"snd\": \"and\",\n","    \"oiving\": \"living\",\n","    \"awwy\": \"away\",\n","    \"cwre\": \"care\",\n","    \"ijust\": \"i just\",\n","    \"ppease\": \"please\",\n","    \"juet\": \"just\",\n","    \"ijust\": \"i just\",\n","    \"wwnt\": \"want\",\n","    \"tefuse\": \"refuse\",\n","    \"tovkill\": \"to kill\",\n","}\n","\n","# Dictionary of words to be replaced\n","detailed_replacements = {\n","    \"i’m\": \"I am\",\n","    \"i'm\": \"I am\",\n","    \"i've\": \"I have\",\n","    \"i'll\": \"I will\",\n","    \"i'd\": \"I would\",\n","    \"didn't\": \"did not\",\n","    \"don't\": \"do not\",\n","    \"doesn't\": \"does not\",\n","    \"can't\": \"can not\",\n","    \"isn't\": \"is not\",\n","    \"aren't\": \"are not\",\n","    \"wasn't\": \"was not\",\n","    \"weren't\": \"were not\",\n","    \"haven't\": \"have not\",\n","    \"hasn't\": \"has not\",\n","    \"hadn't\": \"had not\",\n","    \"won't\": \"will not\",\n","    \"wouldn't\": \"would not\",\n","    \"shouldn't\": \"should not\",\n","    \"couldn't\": \"could not\",\n","    \"mustn't\": \"must not\",\n","    \"she's\": \"she is\",\n","    \"he's\": \"he is\",\n","    \"it's\": \"it is\",\n","    \"that's\": \"that is\",\n","    \"there's\": \"there is\",\n","    \"here's\": \"here is\",\n","    \"who's\": \"who is\",\n","    \"what's\": \"what is\",\n","    \"why's\": \"why is\",\n","    \"how's\": \"how is\",\n","    \"let's\": \"let us\",\n","    \"i'd have\": \"I would have\",\n","    \"could've\": \"could have\",\n","    \"would've\": \"would have\",\n","    \"should've\": \"should have\",\n","    \"we're\": \"we are\",\n","    \"they're\": \"they are\",\n","    \"i'll\": \"I will\",\n","    \"you're\": \"you are\",\n","    \"it's\": \"it is\",\n","\n","    # Version ’ instead of '\n","    \"i’ve\": \"I have\",\n","    \"i’ll\": \"I will\",\n","    \"i’d\": \"I would\",\n","    \"didn’t\": \"did not\",\n","    \"don’t\": \"do not\",\n","    \"doesn’t\": \"does not\",\n","    \"can’t\": \"can not\",\n","    \"isn’t\": \"is not\",\n","    \"aren’t\": \"are not\",\n","    \"wasn’t\": \"was not\",\n","    \"weren’t\": \"were not\",\n","    \"haven’t\": \"have not\",\n","    \"hasn’t\": \"has not\",\n","    \"hadn’t\": \"had not\",\n","    \"won’t\": \"will not\",\n","    \"wouldn’t\": \"would not\",\n","    \"shouldn’t\": \"should not\",\n","    \"couldn’t\": \"could not\",\n","    \"mustn’t\": \"must not\",\n","    \"she’s\": \"she is\",\n","    \"he’s\": \"he is\",\n","    \"it’s\": \"it is\",\n","    \"that’s\": \"that is\",\n","    \"there’s\": \"there is\",\n","    \"here’s\": \"here is\",\n","    \"who’s\": \"who is\",\n","    \"what’s\": \"what is\",\n","    \"why’s\": \"why is\",\n","    \"how’s\": \"how is\",\n","    \"let's\": \"let us\",\n","    \"i’d have\": \"I would have\",\n","    \"could’ve\": \"could have\",\n","    \"would’ve\": \"would have\",\n","    \"should’ve\": \"should have\",\n","    \"we’re\": \"we are\",\n","    \"they’re\": \"they are\",\n","    \"i’ll\": \"I will\",\n","    \"you’re\": \"you are\",\n","    \"it’s\": \"it is\",\n","    \"covid19\": \"covid-19\",\n","    \"covid 19\": \"covid-19\",\n","    \"Covid 19\": \"covid-19\",\n","    \"Covid19\": \"covid-19\",\n","    \"schizoaffective\": \"schizo-affective\",\n","    \"schizo affective\": \"schizo-affective\",\n","    \"thatll\": \"that will\",\n","    \"ibs-d\": \"Ibs-d\",\n","    \"ibsd\": \"Ibs-d\",\n","    \"ibs d\": \"Ibs-d\",\n","    \"Ibs d\": \"Ibs-d\",\n","    \"Ibs-d\": \"Ibs-d\",\n","    \"B-day\": \"birthday\",\n","    \"b-day\": \"birthday\",\n","}\n","\n","# Dictionary of words to be replaced (slang words)\n","slang_dict = {\n","    \"brb\": \"be right back\",\n","    \"dms\": \"direct messages\",\n","    \"lol\": \"laugh out loud\",\n","    \"omg\": \"oh my god\",\n","    \"idk\": \"i don't know\",\n","    \"btw\": \"by the way\",\n","    \"bff\": \"best friends forever\",\n","    \"tbh\": \"to be honest\",\n","    \"imo\": \"in my opinion\",\n","    \"fyi\": \"for your information\",\n","    \"irl\": \"in real life\",\n","    \"yolo\": \"you only live once\",\n","    \"rofl\": \"rolling on the floor laughing\",\n","    \"smh\": \"shaking my head\",\n","    \"nvm\": \"never mind\",\n","    \"gtg\": \"got to go\",\n","    \"ily\": \"i love you\",\n","    \"jk\": \"just kidding\",\n","    \"tmi\": \"too much information\",\n","    \"fomo\": \"fear of missing out\",\n","    \"lmao\": \"laughing my ass off\",\n","    \"ttyl\": \"talk to you later\",\n","    \"icymi\": \"in case you missed it\",\n","    \"rn\": \"right now\",\n","    \"soml\": \"story of my life\",\n","    \"afk\": \"away from keyboard\",\n","    \"bae\": \"before anyone else\",\n","    \"cya\": \"see you\",\n","    \"diy\": \"do it yourself\",\n","    \"ftw\": \"for the win\",\n","    \"gg\": \"good game\",\n","    \"idc\": \"i don't care\",\n","    \"ilysm\": \"i love you so much\",\n","    \"jkl\": \"just kidding lol\",\n","    \"lmk\": \"let me know\",\n","    \"nbd\": \"no big deal\",\n","    \"nm\": \"not much\",\n","    \"nsfw\": \"not safe for work\",\n","    \"omw\": \"on my way\",\n","    \"ppl\": \"people\",\n","    \"tba\": \"to be announced\",\n","    \"tl;dr\": \"too long; didn't read\",\n","    \"wtf\": \"what the fuck\",\n","    \"wyd\": \"what you doing\",\n","    \"sus\": \"suspicious\",\n","    \"vibe\": \"feeling/atmosphere\",\n","    \"stan\": \"obsessive fan\",\n","    \"goat\": \"greatest of all time\",\n","    \"snacc\": \"attractive person\",\n","    \"lit\": \"exciting or amazing\",\n","    \"flex\": \"show off\",\n","    \"noob\": \"newbie\",\n","    \"savage\": \"bold or unapologetic\",\n","    \"mood\": \"current feeling\",\n","    \"clapback\": \"witty response\",\n","    \"thirsty\": \"desperate\",\n","    \"bop\": \"good song\",\n","    \"fam\": \"family or friends\",\n","    \"ship\": \"relationship\",\n","    \"big yikes\": \"major embarrassment\",\n","    \"cap\": \"lie\",\n","    \"no cap\": \"no lie\",\n","    \"bet\": \"sure or okay\",\n","    \"drip\": \"stylish\",\n","    \"cheugy\": \"outdated or uncool\",\n","    \"fit\": \"outfit\",\n","    \"go off\": \"express yourself\",\n","    \"heat\": \"high-quality content\",\n","    \"hundo p\": \"100 percent\",\n","    \"iykyk\": \"if you know, you know\",\n","    \"jomo\": \"joy of missing out\",\n","    \"l\": \"loss or failure\",\n","    \"simp\": \"overly attentive person\",\n","    \"snap\": \"snapchat\",\n","    \"slaps\": \"hits hard (good song)\",\n","    \"troll\": \"provoke online\",\n","    \"v\": \"very\",\n","    \"w\": \"win\",\n","    \"yeet\": \"throw/awesome\",\n","    \"lmao\": \"laughing my ass/arse off\",\n","    \"yo\": \"years old\",\n","    \"ya\": \"you\",\n","}\n","\n","# Dictionary of words to be replaced (slang words)\n","negative_slang_dict = {\n","    \"kms\": \"kill myself\",\n","    \"kys\": \"kill yourself\",\n","    \"s/i\": \"self-injury\",\n","    \"c/t\": \"cutting\",\n","    \"od\": \"overdose\",\n","    \"ed\": \"eating disorder\",\n","    \"anx\": \"anxiety\",\n","    \"depr\": \"depression\",\n","    \"su\": \"suicidal\",\n","    \"bpd\": \"borderline personality disorder\",\n","    \"ts\": \"triggering\",\n","    # \"sad\": \"sadness\",\n","    # \"loner\": \"someone who feels isolated or alone\",\n","    # \"breakdown\": \"mental or emotional collapse\",\n","    # \"blackout\": \"loss of memory or consciousness\",\n","    # \"panic\": \"panic attack\",\n","    # \"meltdown\": \"emotional or mental breakdown\",\n","    # \"overthinking\": \"thinking too much about something\",\n","    # \"worthless\": \"feeling without value\",\n","    # \"hopeless\": \"feeling without hope\",\n","    # \"burnout\": \"extreme stress or exhaustion\",\n","    # \"self-loathing\": \"intense dislike of oneself\",\n","    # \"isolation\": \"feeling isolated or cut off from others\",\n","    # \"ghosted\": \"suddenly cut off communication\",\n","    # \"pain\": \"emotional or physical suffering\",\n","    # \"stress\": \"mental or emotional strain\",\n","    # \"crying\": \"shedding tears due to emotional pain\",\n","    # \"hurt\": \"feeling emotional or physical pain\",\n","    # \"miserable\": \"very unhappy or uncomfortable\",\n","    # \"broken\": \"feeling deeply hurt or defeated\",\n","    # \"trauma\": \"emotional response to a terrible event\",\n","    # \"regret\": \"feeling of sadness over past actions\",\n","    # \"grief\": \"deep sorrow, especially caused by death\",\n","    # \"shame\": \"feeling of guilt or disgrace\",\n","    # \"guilt\": \"feeling responsible for a wrongdoing\"\n","}\n","\n","\n","URL_replacements = {\n","    \"https://www.reddit.com/r/SuicideWatch/comments/jkf5bw/why_my_boyfriend_would_suggest_this_if_he_loves_me/\": \"Why my boyfriend would suggest this if he loves me.\",\n","    \"https://www.reddit.com/r/depression/comments/6izgy2/i_feel_hopeless_and_want_to_die/\": \"I Feel hopeless and want to die.\",\n","    \"https://www.reddit.com/r/AskReddit/comments/n1vroe/serious\\\\_redditors\\\\_who\\\\_have\\\\_lost\\\\_someone\\\\_to/](https://www.reddit.com/r/AskReddit/comments/n1vroe/serious_redditors_who_have_lost_someone_to/))\": \"[Serious] Redditors who have lost someone to suicide, what was it like?\",\n","    \"https://imgur.com/a/EqLEah7\": \"Recent therapy notes. I have since quit my job and haven’t left my apartment in three days.\",\n","    \"https://www.reddit.com/r/SuicideWatch/comments/jhy5yh/please_read_i_am_sad_not_suicidal_but_still/\": \"Please read. I am sad not suicidal but still..\",\n","    \"https://www.reddit.com/r/relationship_advice/comments/jcumcc/i_need_his_affection_and_love_but_i_dont_know_how/\": \"I need his affection and love but I don't know how to Express it right now...please read\",\n","    \"https://www.reddit.com/r/SuicideWatch/comments/kfpjrv/what_are_the_conditions_for_not_feeling_finegood/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf\": \"What are the conditions for not feeling fine/good about death?\",\n","    \"https://www.reddit.com/r/SuicideWatch/comments/knffgq/accidental_unknowing_rapist_and_i_cant_live_with/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf)\": '\"accidental, unknowing rapist\" and i cant live with myself.',\n","    \"https://www.reddit.com/r/SuicideWatch/comments/jja9xt/i_cant_decide_if_i_want_to_wait_until_the_us/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf\": \"i cant decide if i want to wait until the US election results, or if i should just do it now because either way everything that is already shit is only going to get shittier\",\n","}\n","\n","# Function to replace nonsensically consecutive characters\n","def normalize_text(text):\n","    # Replace multiple consecutive parts of the same word\n","    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n","\n","    # Replace multiple repeated combinations of the same word\n","    text = re.sub(r'\\b(\\w+ \\w+)( \\1)+\\b', r'\\1', text)\n","\n","    # Replace words that contain the same character three or more times in a row\n","    return re.sub(r'(.)\\1{2,}', r'\\1', text)\n","\n","def drop_none_text(df):\n","    df['length'] = df['post'].apply(len)\n","    df = df[df['length']!=0]\n","    df = df.drop(columns='length')\n","    return df\n","\n","def is_meaningful_word(word):\n","    # Check if the word exists in the dictionary of English words.\n","    return word.lower() in english_words\n","\n","def extract_meaningful_text(text):\n","    # Regular expressions split sentences\n","    sentences = re.split(r'\\. |\\? |\\! ', text)\n","    meaningful_sentences = []\n","\n","    for sentence in sentences:\n","        words_in_sentence = sentence.split()\n","        if all(is_meaningful_word(word) or word.isdigit() for word in words_in_sentence):\n","            meaningful_sentences.append(sentence)\n","\n","    return '. '.join(meaningful_sentences)\n","\n","def extract_only_number_text(text):\n","    text = text.replace('wouldk', 'would').replace('.,', '.').replace('. ,', '.').replace(' .', '.').replace('h it', 'hit')\n","    text = text.replace('xcuse me', 'excuse me').replace('wer elearning', 'we are learning').replace('gonan', 'gonna').replace('nught', 'night').replace('hi mto', 'him to')\n","    text = text.replace('wasnt', 'was not').replace('wouldve', 'would have').replace('Https/imgur. Com/a/t3wtiov', '').replace('didnt', 'did not').replace('youve', 'you have')\n","    text = text.replace('4kdjejdne sjdjd fuckdjejekieirieiriodidieiridodiodididodidookdkekekdkoeooeoi', 'I').replace('Soi nherently unlikeable.', 'So I am inherently unlikeable.')\n","    text = text.replace('couldve', 'could have').replace('allcmy xanax and effexo', 'all my xanax and effexor')\n","    text = text.replace('Hope my mom callsme selfieh whem shensees my dewdnbody I am the morjimg.', 'Hope my mom calls me selfish when she sees my dead body in the morning.')\n","    text = text.replace('scaared', 'scared').replace('fwiled', 'failed').replace('wxpecter', 'expected').replace('snd', 'and').replace('oiving', 'living')\n","    text = text.replace('awwy', 'away').replace('cwre', 'care').replace('ijust', 'I just').replace('Ppease', 'Please').replace('juet', 'just')\n","    text = text.replace('wwnt', 'want').replace('tefuse', 'refuse').replace('tovkill', 'to kill').replace('callsme', 'calls me').replace('shensees', 'she sees')\n","    text = text.replace('I just turned 17 band', 'I just turned 17 and')\n","    text = text.replace('callckyself', 'call myself').replace('sngry', 'angry').replace('tlaking', 'talking')\n","    text = text.replace('howckuch', 'how much').replace('hebstarted', 'he started').replace('talkikgnsbout', 'talking about')\n","    text = text.replace('hownimnalmost', 'how I am almost').replace('almpdt', 'almost').replace('accountnto', 'account to')\n","    text = text.replace('mynfriend', 'my friend').replace('killijgnmyself', 'killing myself').replace('willcbe', 'will be')\n","    text = text.replace('awrulclife', 'awful life').replace('willcbe', 'will be').replace('youre', 'you are')\n","    text = text.replace('6 mo on', '6 months on').replace('knw', 'know').replace('an yone', 'anyone').replace('wont', 'will not').replace('dont', 'do not').replace('ever yones', 'everyones')\n","    text = text.replace('ever yone', 'everyone').replace('overdosibg', 'overdosing').replace('temme', 'tell me')\n","\n","    # Regular expressions remove meaningless strings and extract meaningful sentences\n","    sentences = re.split(r'\\. |\\? |\\! ', text)\n","    meaningful_sentences = [sentence for sentence in sentences if re.search(r'[a-zA-Z]', sentence)]\n","    return '. '.join(meaningful_sentences)\n","\n","def preprosessing_text(df, url_pattern):\n","\n","    # Replacing URLs\n","    # df = replace_words(df, 'post', URL_replacements)\n","\n","    # Delete lines containing URLs\n","    df = confirm_URL(df, url_pattern)\n","\n","    # Correcting meaningless consecutive words\n","    df['post'] = df['post'].apply(normalize_text)\n","\n","    # Text Processing\n","    df['post'] = df['post'].apply(text_conversion)\n","\n","    # Perform replacements\n","    df = replace_words(df, 'post', replacements)\n","    df = replace_words(df, 'post', detailed_replacements)\n","    df = replace_words(df, 'post', slang_dict)\n","    df = replace_words(df, 'post', negative_slang_dict)\n","\n","    # Capitalize the first letter of each sentence\n","    df['post'] = df['post'].apply(capitalize_sentences_initial)\n","    df['post'] = df['post'].apply(capitalize_i)\n","\n","    df = drop_none_text(df)\n","\n","    # Remove unintelligible words\n","    # df['post'] = df['post'].apply(extract_meaningful_text)\n","\n","    # Delete sentences with only numbers\n","    df['post'] = df['post'].apply(extract_only_number_text)\n","\n","    return df\n","\n","def text_sort(df):\n","    # Sort by length of sentences in POST column\n","    df['length'] = df['post'].apply(len)\n","    df = df[df['length']!=0]\n","    df = df.sort_values(by='length').reset_index(drop=True)\n","    df = df.drop(columns='length')\n","\n","    return df"]},{"cell_type":"code","source":["# !pip install jaconv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1fMGhS5vVwb","executionInfo":{"status":"ok","timestamp":1725700182488,"user_tz":-480,"elapsed":1721,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}},"outputId":"86483b5f-607b-48a9-9efa-a9f36130e8aa"},"id":"w1fMGhS5vVwb","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jaconv in /usr/local/lib/python3.10/dist-packages (0.4.0)\n"]}]},{"cell_type":"code","execution_count":3,"id":"c00921dd-44a3-4d22-89c9-df51077740c2","metadata":{"id":"c00921dd-44a3-4d22-89c9-df51077740c2","executionInfo":{"status":"ok","timestamp":1725700192994,"user_tz":-480,"elapsed":1125,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}}},"outputs":[],"source":["def simple_capitalize_text(text):\n","    text = text.lower()\n","    # Remove white space at the beginning and end of sentences\n","    text = text.strip()\n","\n","    # Replace consecutive spaces with a single space\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = text.replace('\\n', '').replace('\\r', '').replace('\\t', '').replace('\\\\n', '').replace('\\\\r', '').replace('\\\\t', '').replace('\\\\', '')\n","    text = re.sub(r\"(https?|ftp)(:\\/\\/[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+\\$,%#]+)\", \"\" ,text)\n","    text = text.replace('\\n', '').replace('\\r', '').replace('\\t', '').replace('\\\\n', '').replace('\\\\r', '').replace('\\\\t', '').replace('\\\\', '')\n","    return text\n","\n","def simple_fix_text(df, url_pattern):\n","    df = confirm_URL(df, url_pattern)\n","    df['post'] = df['post'].apply(simple_capitalize_text)\n","    return df"]},{"cell_type":"code","execution_count":10,"id":"9ffd72dc-9028-47b8-a397-a43da46e246c","metadata":{"scrolled":true,"id":"9ffd72dc-9028-47b8-a397-a43da46e246c","executionInfo":{"status":"ok","timestamp":1725700869033,"user_tz":-480,"elapsed":534,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers.trainer_utils import set_seed\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, AutoModel, AdamW\n","import numpy as np\n","import pandas as pd\n","from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n","from pprint import pprint\n","from datasets import Dataset\n","from typing import Union\n","from transformers import BatchEncoding, EarlyStoppingCallback\n","from collections import Counter\n","import os\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","import random\n","import json\n","\n","def set_random_seed(seed: int = 42):\n","    set_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    # Settings for reproducibility\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","set_random_seed(42)\n","\n","def report_memory():\n","    print(f\"Allocated: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MiB\")\n","    print(f\"Cached: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MiB\")\n","\n","def cleanup_gpu_memory():\n","    \"\"\"\n","    Function to empty GPU cache, reset CUDA memory, and display memory usage.\n","    \"\"\"\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    torch.cuda.reset_peak_memory_stats()\n","    torch.cuda.reset_accumulated_memory_stats()\n","\n","    print(\"After cleanup:\")\n","    report_memory()\n","\n","def make_vector_data(model, tokenizer, df, device, dir, date, kind):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","\n","    # Execute 10 rows at a time\n","    num_rows_per_df = 10\n","    dfs = [df.iloc[i:i + num_rows_per_df] for i in range(0, len(df), num_rows_per_df)]\n","\n","    print('Start Reasoning')\n","\n","    # List to store data frames after processing\n","    processed_dfs = []\n","    submit_dfs = []\n","\n","    max_length = tokenizer.model_max_length\n","\n","    print('model_max_length:', max_length)\n","\n","    for i, df_part in enumerate(dfs):\n","        set_random_seed(42)\n","\n","        df_part = df_part.reset_index(drop=True)\n","\n","        data_list = df_part['post'].values.tolist()\n","        inputs = tokenizer(data_list, return_tensors='pt', max_length=4096, truncation=True, padding='longest')\n","\n","        # Transfers input data to the same device as the model\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs, output_hidden_states=True)\n","            # 4 vector extraction near the final layer\n","            final_layer_vectors = torch.cat([outputs[\"hidden_states\"][-1*i][:,0] for i in range(1, 4+1)], dim=1)\n","            print(f\"Shape of final_layer_vectors_{kind}: {final_layer_vectors.shape}\")\n","\n","        # mean_vectors = final_layer_vectors.mean(dim=1).cpu().numpy()\n","        final_layer_vectors = final_layer_vectors.cpu().numpy()\n","        df_vec = pd.DataFrame(final_layer_vectors).reset_index(drop=True)\n","\n","        if kind == 'test':\n","            pass\n","        else:\n","            df_vec['post_risk'] = df_part['post_risk']\n","            print('')\n","            print('Completion of vector extraction for training and evaluation data')\n","\n","        ################################################################################################\n","        del data_list, inputs, final_layer_vectors\n","        cleanup_gpu_memory()\n","        ################################################################################################\n","\n","        # Obtaining prediction result\n","        logits = outputs.logits\n","        pred = F.softmax(logits, dim=-1)\n","        df_pred = pd.DataFrame(pred.cpu().numpy(), columns=['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']).reset_index(drop=True)\n","\n","        result_df = pd.DataFrame(pred.cpu().numpy().argmax(axis=1), columns=['suicide risk']).reset_index(drop=True)\n","\n","        df_merged = pd.concat([result_df, df_pred], axis=1)\n","        df_merged['post'] = df_part['post']\n","        df_merged = pd.concat([df_merged, df_vec], axis=1)\n","        submit_dfs.append(df_merged)\n","\n","        ################################################################################################\n","        del logits, outputs, pred, df_pred, result_df, df_part, df_merged, df_vec\n","        cleanup_gpu_memory()\n","        ################################################################################################\n","\n","    df_submit = pd.concat(submit_dfs, ignore_index=True)\n","    df_submit.to_csv(f'{dir}/submission_mental_LongFormer_{kind}_{date}.csv', float_format='%.30f')\n","\n","    ################################################################################################\n","    del submit_dfs, df_submit, dfs\n","    cleanup_gpu_memory()\n","    ################################################################################################\n"]},{"cell_type":"code","source":["# !pip install typing"],"metadata":{"id":"3VQZ0rQyvi17","executionInfo":{"status":"ok","timestamp":1725700205069,"user_tz":-480,"elapsed":523,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}}},"id":"3VQZ0rQyvi17","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":11,"id":"d8be8571-c353-42c8-b65c-091f4487081e","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"d8be8571-c353-42c8-b65c-091f4487081e","executionInfo":{"status":"error","timestamp":1725700898526,"user_tz":-480,"elapsed":26348,"user":{"displayName":"Alex Lee","userId":"06028509031583765820"}},"outputId":"0e103fea-89fa-47ef-8fc3-8bf132324fe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Completion of data preparation\n","Start Reasoning\n","model_max_length: 4096\n","Shape of final_layer_vectors_test: torch.Size([10, 3072])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"invalid argument to reset_peak_memory_stats","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1e4891061d8f>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdir_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"results/{save_date}/{date_cv}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmake_vector_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_complex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-1208b0b0116d>\u001b[0m in \u001b[0;36mmake_vector_data\u001b[0;34m(model, tokenizer, df, device, dir, date, kind)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_layer_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mcleanup_gpu_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-1208b0b0116d>\u001b[0m in \u001b[0;36mcleanup_gpu_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_peak_memory_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_accumulated_memory_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mreset_peak_memory_stats\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \"\"\"\n\u001b[1;32m    321\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_resetPeakMemoryStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: invalid argument to reset_peak_memory_stats"]}],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","set_random_seed(42)\n","\n","# Code Execution Date\n","save_date = 'final'\n","\n","date_complex = f'{save_date}_complex'\n","date_simple = f'{save_date}_simple'\n","\n","num_labels = 4\n","\n","dir_complex = f\"results/{save_date}/{date_complex}\"\n","dir_simple = f\"results/{save_date}/{date_simple}\"\n","\n","set_random_seed(42)\n","\n","df_test = pd.read_excel('./test_100_label_competition.xlsx') # setting your test data\n","df_test_complex = preprosessing_text(df_test, url_pattern)\n","df_test_simple = simple_fix_text(df_test, url_pattern)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print('Completion of data preparation')\n","\n","cv_list1 = [2, 5]\n","cv_list2 = [4]\n","\n","# Complex\n","for cv in cv_list1:\n","\n","    model_dir_cv = f'./gdrive/MyDrive/IEEE Bigdata 2024/1mukumuku/mukumuku/models/model_mental_LongFormer_Smoothing_FocalLoss_ClassBalancedLoss_20240816_cv_{cv}_complex'\n","    date_cv = f'{save_date}_{cv}_complex'\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    ## -- Prediction -- ##\n","    model = (AutoModelForSequenceClassification\n","          .from_pretrained(model_dir_cv, num_labels=num_labels)\n","          .to(device))\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir_cv)\n","    model.eval()\n","\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    make_vector_data(model, tokenizer, df_test_complex, device, dir_cv, date_cv, 'test')\n","\n","    ################################################################################################\n","    del model, tokenizer\n","    cleanup_gpu_memory()\n","    ################################################################################################\n","\n","# Simple\n","for cv in cv_list1:\n","\n","    model_dir_cv = f'./gdrive/MyDrive/IEEE Bigdata 2024/1mukumuku/mukumuku/models/model_mental_LongFormer_Smoothing_FocalLoss_ClassBalancedLoss_20240816_cv_{cv}_simple'\n","    date_cv = f'{save_date}_{cv}_simple'\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    ## -- Prediction -- ##\n","    model = (AutoModelForSequenceClassification\n","          .from_pretrained(model_dir_cv, num_labels=num_labels)\n","          .to(device))\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir_cv)\n","    model.eval()\n","\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    make_vector_data(model, tokenizer, df_test_simple, device, dir_cv, date_cv, 'test')\n","\n","    ################################################################################################\n","    del model, tokenizer\n","    cleanup_gpu_memory()\n","    ################################################################################################\n","\n","# simple\n","for cv in cv_list2:\n","\n","    model_dir_cv = f'./gdrive/MyDrive/IEEE Bigdata 2024/1mukumuku/mukumuku/models/model_mental_LongFormer_Smoothing_FocalLoss_ClassBalancedLoss_20240829_cv_{cv}_simple'\n","    date_cv = f'{save_date}_{cv}_simple'\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    ## -- Prediction -- ##\n","    model = (AutoModelForSequenceClassification\n","          .from_pretrained(model_dir_cv, num_labels=num_labels)\n","          .to(device))\n","    tokenizer = AutoTokenizer.from_pretrained(model_dir_cv)\n","    model.eval()\n","\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    make_vector_data(model, tokenizer, df_test_simple, device, dir_cv, date_cv, 'test')\n","\n","    ################################################################################################\n","    del model, tokenizer\n","    cleanup_gpu_memory()\n","    ################################################################################################"]},{"cell_type":"code","execution_count":null,"id":"17b22dc5-1ca4-4515-ae9e-46f315ae8200","metadata":{"scrolled":true,"id":"17b22dc5-1ca4-4515-ae9e-46f315ae8200","outputId":"68df1e39-33dd-44fa-f08c-962b1e980d80"},"outputs":[{"name":"stdout","output_type":"stream","text":["submits/final\n","(100, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>suicide risk</th>\n","      <th>probability_distribution</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>indicator</td>\n","      <td>[0.7350791096687316, 0.2629762887954711, 0.001...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>attempt</td>\n","      <td>[0.0007071977597661, 0.001842537545599, 0.2968...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>indicator</td>\n","      <td>[0.7391923666000366, 0.2587279379367828, 0.001...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>behavior</td>\n","      <td>[0.0008905654540285, 0.1904413998126983, 0.625...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>indicator</td>\n","      <td>[0.7346532940864562, 0.2614104151725769, 0.002...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>attempt</td>\n","      <td>[0.0007090165745466, 0.0017409325810149, 0.302...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>attempt</td>\n","      <td>[0.0006822702125646, 0.0017445855773985, 0.309...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>indicator</td>\n","      <td>[0.5374879240989685, 0.4417671561241149, 0.020...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>ideation</td>\n","      <td>[0.1815739870071411, 0.6152970790863037, 0.202...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>ideation</td>\n","      <td>[0.1845230460166931, 0.6195836067199707, 0.194...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>"],"text/plain":["    index suicide risk                           probability_distribution\n","0       0    indicator  [0.7350791096687316, 0.2629762887954711, 0.001...\n","1       1      attempt  [0.0007071977597661, 0.001842537545599, 0.2968...\n","2       2    indicator  [0.7391923666000366, 0.2587279379367828, 0.001...\n","3       3     behavior  [0.0008905654540285, 0.1904413998126983, 0.625...\n","4       4    indicator  [0.7346532940864562, 0.2614104151725769, 0.002...\n","..    ...          ...                                                ...\n","95     95      attempt  [0.0007090165745466, 0.0017409325810149, 0.302...\n","96     96      attempt  [0.0006822702125646, 0.0017445855773985, 0.309...\n","97     97    indicator  [0.5374879240989685, 0.4417671561241149, 0.020...\n","98     98     ideation  [0.1815739870071411, 0.6152970790863037, 0.202...\n","99     99     ideation  [0.1845230460166931, 0.6195836067199707, 0.194...\n","\n","[100 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["submits/final\n","(100, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>suicide risk</th>\n","      <th>probability_distribution</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>indicator</td>\n","      <td>[0.707390308380127, 0.2907892167568206, 0.0011...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>attempt</td>\n","      <td>[0.0019300078274682, 0.0024791646283119, 0.323...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>indicator</td>\n","      <td>[0.7122471928596495, 0.2860381007194519, 0.001...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>behavior</td>\n","      <td>[0.0010001907357946, 0.2002476602792739, 0.607...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>indicator</td>\n","      <td>[0.7102662324905396, 0.2877483069896697, 0.001...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>attempt</td>\n","      <td>[0.0008872742764651, 0.0020625968463718, 0.325...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>attempt</td>\n","      <td>[0.0010700814891606, 0.0020848689600825, 0.323...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>ideation</td>\n","      <td>[0.2280506491661071, 0.6068233251571655, 0.164...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>ideation</td>\n","      <td>[0.1970385462045669, 0.6153063178062438, 0.186...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>ideation</td>\n","      <td>[0.1988880783319473, 0.6073114871978759, 0.192...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>"],"text/plain":["    index suicide risk                           probability_distribution\n","0       0    indicator  [0.707390308380127, 0.2907892167568206, 0.0011...\n","1       1      attempt  [0.0019300078274682, 0.0024791646283119, 0.323...\n","2       2    indicator  [0.7122471928596495, 0.2860381007194519, 0.001...\n","3       3     behavior  [0.0010001907357946, 0.2002476602792739, 0.607...\n","4       4    indicator  [0.7102662324905396, 0.2877483069896697, 0.001...\n","..    ...          ...                                                ...\n","95     95      attempt  [0.0008872742764651, 0.0020625968463718, 0.325...\n","96     96      attempt  [0.0010700814891606, 0.0020848689600825, 0.323...\n","97     97     ideation  [0.2280506491661071, 0.6068233251571655, 0.164...\n","98     98     ideation  [0.1970385462045669, 0.6153063178062438, 0.186...\n","99     99     ideation  [0.1988880783319473, 0.6073114871978759, 0.192...\n","\n","[100 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["submits/final\n","(100, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>suicide risk</th>\n","      <th>probability_distribution</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>indicator</td>\n","      <td>[0.645256519317627, 0.3469415605068206, 0.0070...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>attempt</td>\n","      <td>[0.0039697233587503, 0.0050305677577853, 0.265...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>indicator</td>\n","      <td>[0.6604900956153869, 0.3342711627483367, 0.004...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>behavior</td>\n","      <td>[0.0032813425641506, 0.2248504757881164, 0.631...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>indicator</td>\n","      <td>[0.6896944046020507, 0.302069067955017, 0.0049...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>attempt</td>\n","      <td>[0.0029338798485696, 0.0056213098578155, 0.272...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>attempt</td>\n","      <td>[0.0075995665974915, 0.0057050455361604, 0.270...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>ideation</td>\n","      <td>[0.1935986280441284, 0.5960878133773803, 0.208...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>ideation</td>\n","      <td>[0.1679004281759262, 0.6012853980064392, 0.229...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>ideation</td>\n","      <td>[0.1228775903582572, 0.6177815198898315, 0.253...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>"],"text/plain":["    index suicide risk                           probability_distribution\n","0       0    indicator  [0.645256519317627, 0.3469415605068206, 0.0070...\n","1       1      attempt  [0.0039697233587503, 0.0050305677577853, 0.265...\n","2       2    indicator  [0.6604900956153869, 0.3342711627483367, 0.004...\n","3       3     behavior  [0.0032813425641506, 0.2248504757881164, 0.631...\n","4       4    indicator  [0.6896944046020507, 0.302069067955017, 0.0049...\n","..    ...          ...                                                ...\n","95     95      attempt  [0.0029338798485696, 0.0056213098578155, 0.272...\n","96     96      attempt  [0.0075995665974915, 0.0057050455361604, 0.270...\n","97     97     ideation  [0.1935986280441284, 0.5960878133773803, 0.208...\n","98     98     ideation  [0.1679004281759262, 0.6012853980064392, 0.229...\n","99     99     ideation  [0.1228775903582572, 0.6177815198898315, 0.253...\n","\n","[100 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# Complex\n","for cv in cv_list1:\n","\n","    sub_dir = f'submits/{save_date}'\n","\n","    print(sub_dir)\n","    if not os.path.exists(sub_dir):\n","        os.makedirs(sub_dir)\n","\n","    date_cv = f'{save_date}_{cv}_complex'\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    ## -- Summarize -- ##\n","    df_sub1 = pd.read_csv(f'{dir_cv}/submission_mental_LongFormer_test_{date_cv}.csv')\n","\n","    df_sub1 = df_sub1[['suicide risk', 'Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']]\n","    df_sub1.reset_index(drop=False, inplace=True)\n","    df_sub1.rename(columns={'index': 'index'}, inplace=True)\n","    df_sub1['probability_distribution'] = df_sub1[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']].values.tolist()\n","    df_sub1 = df_sub1[['index', 'suicide risk', 'probability_distribution']]\n","\n","    re_conversion_dict = {\n","        0: 'indicator',\n","        1: 'ideation',\n","        2: 'behavior',\n","        3: 'attempt'\n","    }\n","\n","    df_sub1['suicide risk'] = df_sub1['suicide risk'].map(re_conversion_dict)\n","    print(df_sub1.shape)\n","    display(df_sub1)\n","\n","    df_sub1.to_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_model_{date_cv}.xlsx', float_format='%.30f', index=False)\n","\n","# Simple\n","for cv in cv_list2:\n","\n","    sub_dir = f'submits/{save_date}'\n","\n","    print(sub_dir)\n","    if not os.path.exists(sub_dir):\n","        os.makedirs(sub_dir)\n","\n","    date_cv = f'{save_date}_{cv}_simple'\n","    dir_cv = f\"results/{save_date}/{date_cv}\"\n","\n","    ## -- Summarize -- ##\n","    df_sub1 = pd.read_csv(f'{dir_cv}/submission_mental_LongFormer_test_{date_cv}.csv')\n","\n","    df_sub1 = df_sub1[['suicide risk', 'Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']]\n","    df_sub1.reset_index(drop=False, inplace=True)\n","    df_sub1.rename(columns={'index': 'index'}, inplace=True)\n","    df_sub1['probability_distribution'] = df_sub1[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']].values.tolist()\n","    df_sub1 = df_sub1[['index', 'suicide risk', 'probability_distribution']]\n","\n","    re_conversion_dict = {\n","        0: 'indicator',\n","        1: 'ideation',\n","        2: 'behavior',\n","        3: 'attempt'\n","    }\n","\n","    df_sub1['suicide risk'] = df_sub1['suicide risk'].map(re_conversion_dict)\n","    print(df_sub1.shape)\n","    display(df_sub1)\n","\n","    df_sub1.to_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_model_{date_cv}.xlsx', float_format='%.30f', index=False)"]},{"cell_type":"markdown","id":"0082ff0a-c03b-4304-a936-95671f2c5355","metadata":{"id":"0082ff0a-c03b-4304-a936-95671f2c5355"},"source":["# TabPFN"]},{"cell_type":"code","execution_count":null,"id":"b1cce928-abd4-4804-af37-6fb9e02f1030","metadata":{"scrolled":true,"id":"b1cce928-abd4-4804-af37-6fb9e02f1030","outputId":"9c58edc7-7c93-400b-aea3-11ee5b27b8ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Best N_ensemble_configurations: 6\n","Best F1: 0.9032678491957531\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Best N_ensemble_configurations: 1\n","Best F1: 0.9108436435359514\n","Fold 3\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Best N_ensemble_configurations: 1\n","Best F1: 0.9080839548924655\n","Fold 4\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Best N_ensemble_configurations: 5\n","Best F1: 0.9228830067539746\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Best N_ensemble_configurations: 1\n","Best F1: 0.9520859937861826\n","(100, 3)\n"]},{"name":"stderr","output_type":"stream","text":["/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=fp16_inference):\n","/home/m-suzuki-5y3/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>suicide risk</th>\n","      <th>probability_distribution</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>indicator</td>\n","      <td>[0.9799255132675171, 0.01884634420275688, 0.00...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>attempt</td>\n","      <td>[0.0021039159037172794, 0.00040922313928604126...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>indicator</td>\n","      <td>[0.9827612042427063, 0.01612253487110138, 0.00...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>behavior</td>\n","      <td>[0.0008793595479801297, 0.00705487746745348, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>indicator</td>\n","      <td>[0.9832169413566589, 0.01566879265010357, 0.00...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>attempt</td>\n","      <td>[0.0021962837781757116, 0.00032488530268892646...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>attempt</td>\n","      <td>[0.002221649279817939, 0.00046222168020904064,...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>ideation</td>\n","      <td>[0.001271538552828133, 0.9947392344474792, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>ideation</td>\n","      <td>[0.0009504712070338428, 0.9970412254333496, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>ideation</td>\n","      <td>[0.0005550585337914526, 0.9966355562210083, 0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>"],"text/plain":["    index suicide risk                           probability_distribution\n","0       0    indicator  [0.9799255132675171, 0.01884634420275688, 0.00...\n","1       1      attempt  [0.0021039159037172794, 0.00040922313928604126...\n","2       2    indicator  [0.9827612042427063, 0.01612253487110138, 0.00...\n","3       3     behavior  [0.0008793595479801297, 0.00705487746745348, 0...\n","4       4    indicator  [0.9832169413566589, 0.01566879265010357, 0.00...\n","..    ...          ...                                                ...\n","95     95      attempt  [0.0021962837781757116, 0.00032488530268892646...\n","96     96      attempt  [0.002221649279817939, 0.00046222168020904064,...\n","97     97     ideation  [0.001271538552828133, 0.9947392344474792, 0.0...\n","98     98     ideation  [0.0009504712070338428, 0.9970412254333496, 0....\n","99     99     ideation  [0.0005550585337914526, 0.9966355562210083, 0....\n","\n","[100 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","\n","set_random_seed(42)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","use_col_train = ['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3', 'post_risk']\n","use_col_test = ['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","def prediction_TabPFN_simple(use_col_train, use_col_test, date, sub_dir, n):\n","\n","    df_train_vector_simple = pd.read_csv(f'data/20240817_2_simple/submission_mental_LongFormer_train_20240817_2_simple.csv', index_col=0)\n","    df_test_vector_simple = pd.read_csv(f'results/{save_date}/{save_date}_{n}_simple/submission_mental_LongFormer_test_{save_date}_{n}_simple.csv', index_col=0)\n","\n","    ## -- Summarize -- ##\n","    df_train_vector = df_train_vector_simple[use_col_train].reset_index(drop=True)\n","    df_test_vector = df_test_vector_simple[use_col_test].reset_index(drop=True)\n","\n","    data_set = df_train_vector.drop('post_risk', axis=1).reset_index(drop=True)\n","    target_set = df_train_vector['post_risk'].reset_index(drop=True)\n","\n","    cvs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","    bst_scr = 0\n","\n","    cv_results = []\n","\n","    for fold, (train_index, test_index) in enumerate(skf.split(data_set, target_set)):\n","\n","        cvs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","        bst_scr = 0\n","\n","        print(f'Fold {fold + 1}')\n","\n","        X_train, X_valid = data_set.iloc[train_index], data_set.iloc[test_index]\n","        y_train, y_valid = target_set.iloc[train_index], target_set.iloc[test_index]\n","\n","        for cv in cvs:\n","            TabPFN_classifier = TabPFNClassifier(device = device, N_ensemble_configurations=cv)\n","            TabPFN_classifier.fit(X_train, y_train)\n","            y_pred = TabPFN_classifier.predict(X_valid)\n","            F1 = f1_score(y_valid, y_pred, average='weighted')\n","\n","            if bst_scr < F1:\n","                use_cv = cv\n","                bst_scr = F1\n","\n","        print('Best N_ensemble_configurations:', use_cv)\n","        print('Best F1:', bst_scr)\n","\n","        # Creating Submission Files\n","        X_train = df_train_vector.drop('post_risk', axis=1)\n","        y_train = df_train_vector['post_risk']\n","        X_test = df_test_vector\n","\n","        TabPFN_classifier = TabPFNClassifier(device = device, N_ensemble_configurations=use_cv)\n","        TabPFN_classifier.fit(X_train, y_train)\n","\n","        y_pred_proba = TabPFN_classifier.predict_proba(X_test)\n","        y_pred = TabPFN_classifier.predict(X_test)\n","\n","        df_sub = pd.DataFrame(y_pred_proba, columns=[f'Pred_class_{i}' for i in range(y_pred_proba.shape[1])])\n","        cv_results.append(df_sub)\n","\n","    # Combine the results of each CV\n","    all_cv_results = pd.concat(cv_results, axis=0)\n","\n","    # Calculate the average of the results\n","    average_result = all_cv_results.groupby(all_cv_results.index).mean()\n","\n","    conditions = [\n","        (average_result['Pred_class_0'] > average_result[['Pred_class_1', 'Pred_class_2', 'Pred_class_3']].max(axis=1)),\n","        (average_result['Pred_class_1'] > average_result[['Pred_class_0', 'Pred_class_2', 'Pred_class_3']].max(axis=1)),\n","        (average_result['Pred_class_2'] > average_result[['Pred_class_0', 'Pred_class_1', 'Pred_class_3']].max(axis=1)),\n","        (average_result['Pred_class_3'] > average_result[['Pred_class_0', 'Pred_class_1', 'Pred_class_2']].max(axis=1))\n","    ]\n","    choices = ['indicator', 'ideation', 'behavior', 'attempt']\n","\n","    average_result['suicide risk'] = np.select(conditions, choices, default='unknown')\n","\n","    average_result = average_result[['suicide risk', 'Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']]\n","    average_result.reset_index(drop=False, inplace=True)\n","    average_result.rename(columns={'index': 'index'}, inplace=True)\n","    average_result['probability_distribution'] = average_result[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']].values.tolist()\n","    average_result = average_result[['index', 'suicide risk', 'probability_distribution']]\n","\n","    print(average_result.shape)\n","    display(average_result)\n","\n","    average_result.to_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_TabPFN_{date}.xlsx', float_format='%.30f', index=False)\n","\n","date = f'{save_date}_2_simple'\n","prediction_TabPFN_simple(use_col_train, use_col_test, date, sub_dir, 2)"]},{"cell_type":"markdown","id":"9d9a5e74-ab14-4013-806d-ae0f05be2740","metadata":{"id":"9d9a5e74-ab14-4013-806d-ae0f05be2740"},"source":["# Final result"]},{"cell_type":"code","execution_count":null,"id":"0009c41e-ba3f-43b6-9cc3-4a79bf6d0e26","metadata":{"id":"0009c41e-ba3f-43b6-9cc3-4a79bf6d0e26"},"outputs":[],"source":["import os\n","import ast\n","import numpy as np\n","\n","df1 = pd.read_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_model_{save_date}_2_complex.xlsx') # 0.7326\n","df2 = pd.read_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_model_{save_date}_5_complex.xlsx') # 0.7349\n","df3 = pd.read_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_TabPFN_{save_date}_2_simple.xlsx') # 0.7359\n","df4 = pd.read_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_model_{save_date}_4_simple.xlsx') # 0.7326\n","\n","df1.set_index('index', inplace=True)\n","df2.set_index('index', inplace=True)\n","df3.set_index('index', inplace=True)\n","df4.set_index('index', inplace=True)\n","\n","df1['probability_distribution'] = df1['probability_distribution'].apply(ast.literal_eval)\n","df2['probability_distribution'] = df2['probability_distribution'].apply(ast.literal_eval)\n","df3['probability_distribution'] = df3['probability_distribution'].apply(ast.literal_eval)\n","df4['probability_distribution'] = df4['probability_distribution'].apply(ast.literal_eval)\n","\n","df1[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']] = pd.DataFrame(df1['probability_distribution'].tolist(), index=df1.index)\n","df2[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']] = pd.DataFrame(df2['probability_distribution'].tolist(), index=df2.index)\n","df3[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']] = pd.DataFrame(df3['probability_distribution'].tolist(), index=df3.index)\n","df4[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']] = pd.DataFrame(df4['probability_distribution'].tolist(), index=df4.index)"]},{"cell_type":"code","execution_count":null,"id":"e7e62887-71a3-4dd0-bc86-8932689d678b","metadata":{"id":"e7e62887-71a3-4dd0-bc86-8932689d678b","outputId":"0909d4bb-b584-43ec-e2ab-09097b61dc9b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>suicide risk</th>\n","      <th>probability_distribution</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>indicator</td>\n","      <td>[0.7669128626585007, 0.2298883525654673, 0.002...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>attempt</td>\n","      <td>[0.0021777112124254697, 0.00244037326774556, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>indicator</td>\n","      <td>[0.7736727148294449, 0.2237899340689182, 0.001...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>behavior</td>\n","      <td>[0.0015128645754884573, 0.15564860333688552, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>indicator</td>\n","      <td>[0.7794577181339264, 0.21672414569184179, 0.00...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>attempt</td>\n","      <td>[0.001681613619439253, 0.0024374311469727815, ...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>attempt</td>\n","      <td>[0.00289339189475866, 0.00249918043846261, 0.2...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>ideation</td>\n","      <td>[0.24010218496550803, 0.659854382276535, 0.099...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>ideation</td>\n","      <td>[0.13686585814866703, 0.7072325050830841, 0.15...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>ideation</td>\n","      <td>[0.12671094331017227, 0.7103280425071716, 0.16...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>"],"text/plain":["    index suicide risk                           probability_distribution\n","0       0    indicator  [0.7669128626585007, 0.2298883525654673, 0.002...\n","1       1      attempt  [0.0021777112124254697, 0.00244037326774556, 0...\n","2       2    indicator  [0.7736727148294449, 0.2237899340689182, 0.001...\n","3       3     behavior  [0.0015128645754884573, 0.15564860333688552, 0...\n","4       4    indicator  [0.7794577181339264, 0.21672414569184179, 0.00...\n","..    ...          ...                                                ...\n","95     95      attempt  [0.001681613619439253, 0.0024374311469727815, ...\n","96     96      attempt  [0.00289339189475866, 0.00249918043846261, 0.2...\n","97     97     ideation  [0.24010218496550803, 0.659854382276535, 0.099...\n","98     98     ideation  [0.13686585814866703, 0.7072325050830841, 0.15...\n","99     99     ideation  [0.12671094331017227, 0.7103280425071716, 0.16...\n","\n","[100 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["df_avg = (df1[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']] + df2[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']]\n","         + df3[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']] + df4[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']]) / 4\n","\n","\n","# Store the name of the class with the highest predicted probability in the SUICIDE RISK column\n","conditions = [\n","    (df_avg['Pred_class_0'] > df_avg[['Pred_class_1', 'Pred_class_2', 'Pred_class_3']].max(axis=1)),\n","    (df_avg['Pred_class_1'] > df_avg[['Pred_class_0', 'Pred_class_2', 'Pred_class_3']].max(axis=1)),\n","    (df_avg['Pred_class_2'] > df_avg[['Pred_class_0', 'Pred_class_1', 'Pred_class_3']].max(axis=1)),\n","    (df_avg['Pred_class_3'] > df_avg[['Pred_class_0', 'Pred_class_1', 'Pred_class_2']].max(axis=1))\n","]\n","choices = ['indicator', 'ideation', 'behavior', 'attempt']\n","\n","df_avg['suicide risk'] = np.select(conditions, choices, default='unknown')\n","\n","df_avg = df_avg[['suicide risk', 'Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']]\n","df_avg.reset_index(drop=False, inplace=True)\n","df_avg.rename(columns={'index': 'index'}, inplace=True)\n","df_avg['probability_distribution'] = df_avg[['Pred_class_0', 'Pred_class_1', 'Pred_class_2', 'Pred_class_3']].values.tolist()\n","df_avg = df_avg[['index', 'suicide risk', 'probability_distribution']]\n","\n","df_avg.to_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_CV_simple_complex_final.xlsx', float_format='%.30f', index=False)\n","display(df_avg)"]},{"cell_type":"markdown","id":"c20a0e88-de89-4127-af0f-aa17f99ef03f","metadata":{"id":"c20a0e88-de89-4127-af0f-aa17f99ef03f"},"source":["# Reproducibility Confirmation"]},{"cell_type":"code","execution_count":null,"id":"a2dc777f-cbb4-4d95-8759-c66f99bbba27","metadata":{"id":"a2dc777f-cbb4-4d95-8759-c66f99bbba27","outputId":"b755c1b8-b307-4392-d918-39ffbc6deeca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success!!\n"]}],"source":["df_confirm = pd.read_excel('data/confirm_data/mukumuku_submission_mental_LongFormer_CV_simple_complex_top4.xlsx')\n","\n","df_result = pd.read_excel(f'{sub_dir}/mukumuku_submission_mental_LongFormer_CV_simple_complex_final.xlsx')\n","\n","different_rows = df_confirm[df_confirm['suicide risk'] != df_result['suicide risk']]\n","\n","# Reproducibility Confirmation\n","if different_rows.empty:\n","    print(\"Success!!\")\n","else:\n","    print(different_rows)"]},{"cell_type":"code","execution_count":null,"id":"1149d7e4-39fa-45d5-a8e2-740a0cbc83b1","metadata":{"id":"1149d7e4-39fa-45d5-a8e2-740a0cbc83b1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"eccc170e-1d70-44de-9739-61e4b00f942d","metadata":{"id":"eccc170e-1d70-44de-9739-61e4b00f942d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"48d324ca-6172-498a-9bc9-4166112b7bc1","metadata":{"id":"48d324ca-6172-498a-9bc9-4166112b7bc1"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python (myvenv)","language":"python","name":"myenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}